import os

from torch.utils.data import DataLoader

from data.dataset import DEMDataset
from data.transforms import get_transforms


def collate_fn(batch: list) -> tuple:
    """
    Collate multiple images and targets (data samples) into a single batch to handle data loading.
    :param batch: list of data samples
    :return: tuple of collated batch
    """
    images, targets = zip(*batch)
    return images, targets


def get_dataloader(subset: str, dataset_dir: str, image_size: int, batch_size: int, num_workers: int) -> DataLoader:
    """
    Get training, validation or testing dataloader. Load chosen subset from given directory and perform its composition
    as *PyTorch* indexable *Dataset* subclass. Pre-wrap images and annotations into batches. Apply default transforms
    and shuffling to training or validation subset, leave data as is if it is testing subset.
    :param subset: either 'train', 'val' or 'test'
    :param dataset_dir: path to dataset generated by **extract_data.ipynb**
    :param image_size: image size for resizing
    :param batch_size: number of images and annotations per batch
    :param num_workers: number of workers for dataloader
    :return: chosen subset dataloader
    """
    images_dir = os.path.join(dataset_dir, f'images/{subset}/')
    annotations_dir = os.path.join(dataset_dir, f'annotations/{subset}/')

    dataset = (DEMDataset(images_dir, annotations_dir, image_size, get_transforms(image_size))
               if subset in ('train', 'val') else DEMDataset(images_dir, annotations_dir, image_size, transforms=None))

    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers,
                            collate_fn=collate_fn, shuffle=subset in ('train', 'val'))

    return dataloader
