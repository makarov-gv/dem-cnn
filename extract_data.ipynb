{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e598cbc2-a328-4b66-9485-f0968237f90e",
   "metadata": {},
   "source": [
    "# Extract Data\n",
    "\n",
    "Ноутбук позволяет извлечь данные для создания датасета. В дальнейшем созданный датасет можно использовать при обучении DEM CNN. Для корректной работы нужен ЦММ в формате **GeoTIFF**, а также векторные фигуры в формате **Shapefile**. В фигурах должны быть слои: один с произвольным названием, не представляющим из себя цифру (например, *Segmentation*); остальные с названиями в виде цифр, характеризующих ID класса объекта. В рамках проекта DEM CNN обучен на 10 классах, поэтому необходимы слои с *1* по *10* непосредственно. Названия конкретных фигур не учитываются.\n",
    "\n",
    "Слой с произвольным названием, *Segmentation*, будет служить для обозначения полезных данных для создания датасета. Всё растровое содержимое вне полигонов этого слоя будет игнорироваться.\n",
    "\n",
    "Остальные слои должны содержать 4-точечные полигоны объектов непосредственно. Эти полигоны будут аппроксимироваться до горизонтальных ограничивающих рамок.\n",
    "\n",
    "Датасеты конкатенируются, поэтому ноутбук можно запускать несколько раз на разных ЦММ. При этом уже имеющиеся данные перезаписываются в случае использования одних и тех же параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f385e-6c25-4fb2-afd4-ea9dd66d00ac",
   "metadata": {},
   "source": [
    "## Подготовка\n",
    "\n",
    "Скачиваем необходимые для работы библиотеки. Импортируем их. Задаём пути к ЦММ и векторным фигурам, а также к папке, куда будет сохраняться датасет. Задаём жесткие параметры датасета, рассчитываем окно и подбираем масштабирующие коэффициенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb3d46b-bcdb-4bff-9ecf-5c5176ab588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: shapely in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (2.0.6)\n",
      "Requirement already satisfied: numpy in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: rasterio in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (1.3.10)\n",
      "Requirement already satisfied: tqdm in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (4.66.4)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from geopandas) (0.9.0)\n",
      "Requirement already satisfied: packaging in /home/makarov/.local/lib/python3.11/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from geopandas) (2.2.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: affine in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from rasterio) (24.2.0)\n",
      "Requirement already satisfied: certifi in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from rasterio) (2024.8.30)\n",
      "Requirement already satisfied: click>=4.0 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from rasterio) (72.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from snuggs>=1.4.1->rasterio) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/makarov/miniconda3/envs/dem_cnn/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install geopandas shapely numpy rasterio tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ded3c2e-3d33-4868-9bb7-f67b0cdf6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.features import rasterize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b822249697fdc583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = os.path.abspath('dataset/')\n",
    "output_images = os.path.join(output, 'images/')\n",
    "output_annotations = os.path.join(output, 'annotations/')\n",
    "if not os.path.exists(output):\n",
    "    [os.mkdir(dir_) for dir_ in (output, output_images, output_annotations)]\n",
    "else:\n",
    "    [os.mkdir(dir_) for dir_ in (output_images, output_annotations) if not os.path.exists(dir_)]\n",
    "        \n",
    "train_images, val_images, test_images = [os.path.join(output, 'images/', subset) for subset in ('train/', 'val/', 'test/')]\n",
    "train_annotations, val_annotations, test_annotations = [os.path.join(output, 'annotations/', subset) for subset in ('train/', 'val/', 'test/')]\n",
    "[os.mkdir(dir_) for dir_ in (train_images, val_images, test_images, train_annotations, val_annotations, test_annotations) if not os.path.exists(dir_)]\n",
    "\n",
    "os.path.exists(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c33408-2bdf-4bd4-a4b8-dba7fd1019c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = os.path.abspath('dataset/dem.tif')  # it is implied that dem variable will be switched with correct path to GeoTIFF\n",
    "shapes = os.path.abspath('dataset/shapes.shp')  # it is implied that shapes variable will be switched with correct path to Shapefile\n",
    "codename = 'query'  # codename for certain DEM to make dataset more distinctive if it was extracted from multiple projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb112193-0b7c-444b-b3b2-bc1d48c4acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_GSD: float = 0.05  # GSD (m/pixel) that will serve as reference when inferencing a model\n",
    "INFERENCE_SIZE: int = 640  # size of each image, preferably from 640 or 1280 (the same as the size of input tensor) \n",
    "STEP_COEFF: float = 0.66  # coefficient for step size calculation, e.g. 0.66 * 640 = 422 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12fd0a9-72c8-4ae6-a8b6-1b66ac810faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rasterio.open(dem)\n",
    "gdf = gpd.read_file(shapes)\n",
    "\n",
    "gdf.drop(gdf.columns.difference(['LAYER', 'geometry']), axis=1, inplace=True)\n",
    "gdf.rename(columns={'LAYER':'id'}, inplace=True)\n",
    "\n",
    "objects = gdf[gdf.id.isin([str(i + 1) for i in range(10)])]  # if layer label (ID) is a digit (from 1 up to 10), than it is an object\n",
    "seg = gdf[~gdf.id.isin([str(i + 1) for i in range(10)])]  # it is a segmentation mask otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3082ed5-47a3-4b36-960f-794bec9d0519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041723176431440884\n"
     ]
    }
   ],
   "source": [
    "if src.crs == {'init': 'EPSG:4326'}:\n",
    "    lat, lon = src.xy(src.width / 2., src.height / 2.)\n",
    "    code = int(32700 - round((45. + lon) / 90.) * 100 + round((183. + lat) / 6.))  # UTM zone calculus formula\n",
    "    l, b, r, t = rasterio.warp.transform_bounds(src.crs, {'init': f'EPSG:{code}'}, *src.bounds)\n",
    "    GSD = np.average(((r - l) / src.width, (t - b) / src.height))\n",
    "else:\n",
    "    GSD = np.average(src.res)\n",
    "\n",
    "meta = src.meta\n",
    "meta['height'] = meta['width'] = INFERENCE_SIZE\n",
    "\n",
    "if GSD > DESIRED_GSD:  # as mentioned, worse GSD than your desired GSD makes dataset suboptimal\n",
    "    raise ValueError(f'The resolution in the input data {GSD} is too bad')\n",
    "else:\n",
    "    print(GSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beedd8a1-6e97-43b5-890e-10ad8ccf73f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(766, 0.835509138381201, 505, 34340, 25755)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(INFERENCE_SIZE * DESIRED_GSD / GSD)  # window size relative to both desired and real GSD\n",
    "resize_ratio = INFERENCE_SIZE / size  # to resize annotations pixel-wise coordinates\n",
    "step = int(STEP_COEFF * size)  # step between windows\n",
    "\n",
    "steps_x_ = int(np.ceil(src.width / step))\n",
    "steps_y_ = int(np.ceil(src.height / step))\n",
    "steps_x = steps_x_ * step\n",
    "steps_y = steps_y_ * step\n",
    "\n",
    "size, resize_ratio, step, steps_x, steps_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fafe0eb-a07f-4efc-90ae-ec5fd866d781",
   "metadata": {},
   "source": [
    "## Вспомогательные функции\n",
    "\n",
    "Загрузка изображения и выжигание полигонов сегментационной маски. Формирование аннотаций на основе координат полигонов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b90dbe-d35c-42d4-9987-9f40f45ba7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(src: rasterio.io.DatasetReader, window: Window, window_polygon: geometry.Polygon, seg: gpd.GeoDataFrame) -> np.ndarray:\n",
    "    image = src.read(window=window)\n",
    "\n",
    "    mask = rasterize([intersection for intersection in window_polygon.intersection(seg.geometry) if not intersection.is_empty], \n",
    "                     out_shape=image.shape[1:], transform=src.window_transform(window), all_touched=True, dtype=np.float32)\n",
    "    if not mask.sum() / mask.size >= 0.1:  # sanity check to ignore uninformative DEM regions with area of mask being less than 10%\n",
    "        return np.zeros_like(image)\n",
    "    \n",
    "    image = np.where(mask, image, src.nodata if src.nodata else 0.)\n",
    "\n",
    "    return image\n",
    "\n",
    "def get_annotations(polygon: geometry.Polygon, objects: gpd.GeoDataFrame) -> list:\n",
    "    annotations = []\n",
    "    for _, object in objects[polygon.intersects(objects.geometry)].iterrows():\n",
    "        intersection = polygon.intersection(object.geometry)\n",
    "        x_min, y_max, x_max, y_min = intersection.bounds\n",
    "        y_min, x_min = src.index(x_min, y_min)\n",
    "        y_max, x_max = src.index(x_max, y_max)\n",
    "        x_min, x_max = x_min - x, x_max - x\n",
    "        y_min, y_max = y_min - y, y_max - y\n",
    "        \n",
    "        xyxy = [max(min(coord, size), 0.) * resize_ratio for coord in (x_min, y_min, x_max, y_max)]\n",
    "        if (xyxy[2] - xyxy[0]) * (xyxy[3] - xyxy[1]) > 100.:  # sanity check to ignore bounding boxes with area less than 100 squared pixels\n",
    "            annotations.append((object.id, *xyxy))\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f3fd7-404c-41a0-9004-4563147c2277",
   "metadata": {},
   "source": [
    "## Создание датасета\n",
    "\n",
    "В этом цикле алгоритмом скользящего окна проходимся по ЦММ, находим полезные участки относительно сегментационной маски и создаём на их основе изображения и аннотации. Сохраняем данные в папку для датасета. Участки без полезных данных (или те, где полезных данных меньше 10%) игнорируются скользящим окном (проверка идёт по маске ЦММ, а не растру)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb3856f-0f70-411d-a80b-761719a8d1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3389it [00:22, 295.51it/s]                          "
     ]
    }
   ],
   "source": [
    "annotated = []  # to store files that have objects in them\n",
    "unannotated = []  # to sotre files that do not have any objects\n",
    "\n",
    "pbar = tqdm(total=(steps_x_ - 1) * (steps_y_ - 1))\n",
    "\n",
    "for y in range(0, steps_y, step):\n",
    "    for x in range(0, steps_x, step):\n",
    "        pbar.update()\n",
    "        \n",
    "        window = Window(x, y, size, size)\n",
    "        if not src.read_masks(window=window).any():\n",
    "            continue\n",
    "\n",
    "        window_polygon = geometry.Polygon((src.xy(y, x), src.xy(y + size, x), src.xy(y + size, x + size), src.xy(y, x + size), src.xy(y, x)))\n",
    "        if not seg.geometry.intersects(window_polygon).any():\n",
    "            continue\n",
    "\n",
    "        formatted_coords = [str(round(src.xy(y, x)[i], 4)) for i in (0, 1)]\n",
    "\n",
    "        image = get_image(src, window, window_polygon, seg)\n",
    "        if not image.any():\n",
    "            continue\n",
    "\n",
    "        annotations = get_annotations(window_polygon, objects)\n",
    "\n",
    "        file = f'{codename}{formatted_coords[0]}_{formatted_coords[1]}_{size}'\n",
    "        if file not in annotated and file not in unannotated:  # TODO: check why without this statement notebook will fault sometimes\n",
    "            if annotations:\n",
    "                annotated.append(file)\n",
    "            else:\n",
    "                unannotated.append(file)\n",
    "        \n",
    "        image_path = os.path.join(output_images, f'{file}.tif')  # unique name that consists of formatted top left corner coordinates\n",
    "        with rasterio.open(image_path, 'w', **meta) as dest:\n",
    "            dest.write(image)\n",
    "\n",
    "        if annotations:\n",
    "            annotation_path = os.path.join(output_annotations, f'{file}.txt')  # same unique name as that of the image\n",
    "            with open(annotation_path, 'w', encoding='utf-8') as file:\n",
    "                file.writelines(f'{id}\\t{x_min}\\t{y_min}\\t{x_max}\\t{y_max}\\n' for id, x_min, y_min, x_max, y_max in annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f631ceaf-6f22-4136-b3c1-3dd6f70558e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src.close()  # uncomment to properly close GeoTIFF just in case it causes errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a72bed-deb5-44fd-8b98-5d38c11f6d09",
   "metadata": {},
   "source": [
    "## Организация субсетов\n",
    "\n",
    "Случайно перетасовываем все пары изображение+аннотации, после чего производим разбивку на тренировочный, валидационный и тестировочный субсеты в соотношении 70%, 20% и 10% соответственно. К полученным данным добавляем неаннотированные изображения в размере 40% от субсета (например, при 50 тренировочных аннотированных изображениях к ним добавится 20 неаннотированных). Сортируем субсеты по одноименным директориям. Удаляем лишние неаннотированные изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5477b9a7-dd9b-4d4c-9fb6-f784686cdf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3 2\n",
      "12 4 2\n"
     ]
    }
   ],
   "source": [
    "train_ratio, val_ratio, test_ratio = 0.7, 0.2, 0.1\n",
    "unannotated_ratio = 0.4\n",
    "\n",
    "shuffle(annotated)  # optional, comment to leave annotated data as is\n",
    "shuffle(unannotated)  # optional, comment to leave unannotated data as is\n",
    "\n",
    "train, val, test = np.split(annotated, [int(len(annotated) * train_ratio), int(len(annotated) * (train_ratio + val_ratio))])\n",
    "train, val, test = train.tolist(), val.tolist(), test.tolist()\n",
    "\n",
    "print(len(train), len(val), len(test))\n",
    "\n",
    "train_len, val_len, test_len = int(unannotated_ratio * len(train)), int(unannotated_ratio * len(val)), int(unannotated_ratio * len(test))\n",
    "train += unannotated[:train_len]\n",
    "val += unannotated[train_len + 1:train_len + 1 + val_len]\n",
    "test += unannotated[train_len + 1 + val_len + 1:train_len + 1 + val_len + 1 + test_len]\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c46b19b-7b1a-4d8e-8d3c-4fc5866cbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset, num in ((train, 0), (val, 1), (test, 2)):\n",
    "    for file in subset:\n",
    "        image_path = os.path.join(output_images, f'{file}.tif')\n",
    "        new_image_path = os.path.join(train_images if num == 0 else val_images if num == 1 else test_images, f'{file}.tif')\n",
    "        os.replace(image_path, new_image_path)\n",
    "        \n",
    "        annotation_path = os.path.join(output_annotations, f'{file}.txt')\n",
    "        if os.path.exists(annotation_path):\n",
    "            new_annotation_path = os.path.join(train_annotations if num == 0 else val_annotations if num == 1 else test_annotations, f'{file}.txt')\n",
    "            os.replace(annotation_path, new_annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff1ad8f-a345-43e7-919c-f32e58d75bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(output_images):\n",
    "    path = os.path.join(output_images, file)\n",
    "    if os.path.isfile(path):\n",
    "        os.remove(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
